{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup code (not important) - Run this cell by pressing \"Shift + Enter\"\n",
    "\n",
    "\n",
    "\n",
    "!pip install -qq gym==0.23.0\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, Optional, Iterable, Callable\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import torch\n",
    "from matplotlib import animation\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "\n",
    "import pygame\n",
    "from pygame import gfxdraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_video(frames):\n",
    "    # Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    matplotlib.use(orig_backend)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "        im.set_data(frame)\n",
    "        return [im]\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                    interval=50, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "\n",
    "def seed_everything(env: gym.Env, seed: int = 42) -> None:\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def plot_stats(stats):\n",
    "    rows = len(stats)\n",
    "    cols = 1\n",
    "\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(12, 6))\n",
    "\n",
    "    for i, key in enumerate(stats):\n",
    "        vals = stats[key]\n",
    "        vals = [np.mean(vals[i-10:i+10]) for i in range(10, len(vals)-10)]\n",
    "        if len(stats) > 1:\n",
    "            ax[i].plot(range(len(vals)), vals)\n",
    "            ax[i].set_title(key, size=18)\n",
    "        else:\n",
    "            ax.plot(range(len(vals)), vals)\n",
    "            ax.set_title(key, size=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_policy_network(env, policy, episodes=10):\n",
    "    frames = []\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        frames.append(env.render())\n",
    "\n",
    "        while not done:\n",
    "            state = torch.from_numpy(state).unsqueeze(0).float()\n",
    "            action = policy(state).multinomial(1).item()\n",
    "            next_state, _, done, _ = env.step(action)\n",
    "            img = env.render()\n",
    "            frames.append(img)\n",
    "            state = next_state\n",
    "\n",
    "    return display_video(frames)\n",
    "\n",
    "\n",
    "def plot_action_probs(probs, labels):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(labels, probs, color ='orange')\n",
    "    plt.title(\"$\\pi(s)$\", size=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gym\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "\n",
    "# test_policy_network, seed_everything, plot_state, plot_action_probs, ParallelEnv, ParallelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2086f805e10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnvElEQVR4nO3df3SU1YH/8c/kJ4QwEwMkk5QEUSgQIdjyI8zaunRJCRBdWeMetSxglwNHNvEUYimmS0XsrnFxz/qjRfijXXHPkdLSI7pSQTFIqDX8MCXLL02FpQ0umQTly0zAJpDM/f7h4TkdGZEJIXOHvF/nPOdknnvnee5zT8J8uPc+z7iMMUYAAAAWSYh1AwAAAD6PgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArBPTgLJmzRrdeOON6tevn4qKirR3795YNgcAAFgiZgHll7/8pSorK7Vy5Ur9/ve/1/jx41VSUqLW1tZYNQkAAFjCFasvCywqKtKkSZP005/+VJIUCoWUl5enhx56SI888kgsmgQAACyRFIuTnj9/XvX19aqqqnL2JSQkqLi4WHV1dZfU7+joUEdHh/M6FArp9OnTGjRokFwuV6+0GQAAXB1jjNra2pSbm6uEhMtP4sQkoHz88cfq6upSdnZ22P7s7Gx98MEHl9Svrq7WqlWreqt5AADgGjpx4oSGDh162ToxCSjRqqqqUmVlpfM6EAgoPz9fJ06ckNvtjmHLAADAlQoGg8rLy9PAgQO/tG5MAsrgwYOVmJiolpaWsP0tLS3yer2X1E9NTVVqauol+91uNwEFAIA4cyXLM2JyF09KSoomTJigmpoaZ18oFFJNTY18Pl8smgQAACwSsymeyspKzZ8/XxMnTtTkyZP1zDPP6Ny5c/rud78bqyYBAABLxCyg3HvvvTp16pQeffRR+f1+3Xrrrdq2bdslC2cBAEDfE7PnoFyNYDAoj8ejQCDAGhQAAOJENJ/ffBcPAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1ejygPPbYY3K5XGHb6NGjnfL29naVl5dr0KBBSk9PV1lZmVpaWnq6GQAAII5dkxGUW265Rc3Nzc72zjvvOGVLly7Va6+9pk2bNqm2tlYnT57U3XfffS2aAQAA4lTSNTloUpK8Xu8l+wOBgH7+859rw4YN+pu/+RtJ0gsvvKAxY8Zo9+7dmjJlyrVoDgAAiDPXZATlww8/VG5urm666SbNmTNHTU1NkqT6+npduHBBxcXFTt3Ro0crPz9fdXV1X3i8jo4OBYPBsA0AAFy/ejygFBUVaf369dq2bZvWrl2r48eP65vf/Kba2trk9/uVkpKijIyMsPdkZ2fL7/d/4TGrq6vl8XicLS8vr6ebDQAALNLjUzwzZ850fi4sLFRRUZGGDRumX/3qV+rfv3+3jllVVaXKykrndTAYJKQAAHAdu+a3GWdkZOirX/2qjh49Kq/Xq/Pnz+vMmTNhdVpaWiKuWbkoNTVVbrc7bAMAANevax5Qzp49q2PHjiknJ0cTJkxQcnKyampqnPLGxkY1NTXJ5/Nd66YAAIA40eNTPN///vd15513atiwYTp58qRWrlypxMRE3X///fJ4PFqwYIEqKyuVmZkpt9uthx56SD6fjzt4AACAo8cDykcffaT7779fn3zyiYYMGaJvfOMb2r17t4YMGSJJevrpp5WQkKCysjJ1dHSopKREzz//fE83AwAAxDGXMcbEuhHRCgaD8ng8CgQCrEcBACBORPP5zXfxAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsE3VA2bVrl+68807l5ubK5XLplVdeCSs3xujRRx9VTk6O+vfvr+LiYn344YdhdU6fPq05c+bI7XYrIyNDCxYs0NmzZ6/qQgAAwPUj6oBy7tw5jR8/XmvWrIlYvnr1aj333HNat26d9uzZowEDBqikpETt7e1OnTlz5ujw4cPavn27tmzZol27dmnRokXdvwoAAHBdcRljTLff7HJp8+bNmj17tqTPRk9yc3P18MMP6/vf/74kKRAIKDs7W+vXr9d9992n999/XwUFBdq3b58mTpwoSdq2bZtmzZqljz76SLm5uV963mAwKI/Ho0AgILfb3d3mAwCAXhTN53ePrkE5fvy4/H6/iouLnX0ej0dFRUWqq6uTJNXV1SkjI8MJJ5JUXFyshIQE7dmzJ+JxOzo6FAwGwzYAAHD96tGA4vf7JUnZ2dlh+7Ozs50yv9+vrKyssPKkpCRlZmY6dT6vurpaHo/H2fLy8nqy2QAAwDJxcRdPVVWVAoGAs504cSLWTQIAANdQjwYUr9crSWppaQnb39LS4pR5vV61traGlXd2dur06dNOnc9LTU2V2+0O2wAAwPWrRwPK8OHD5fV6VVNT4+wLBoPas2ePfD6fJMnn8+nMmTOqr6936uzYsUOhUEhFRUU92RwAABCnkqJ9w9mzZ3X06FHn9fHjx9XQ0KDMzEzl5+dryZIl+pd/+ReNHDlSw4cP149+9CPl5uY6d/qMGTNGM2bM0MKFC7Vu3TpduHBBFRUVuu+++67oDh4AAHD9izqgvPfee/rWt77lvK6srJQkzZ8/X+vXr9cPfvADnTt3TosWLdKZM2f0jW98Q9u2bVO/fv2c97z00kuqqKjQtGnTlJCQoLKyMj333HM9cDkAAOB6cFXPQYkVnoMCAED8idlzUAAAAHoCAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHWiDii7du3SnXfeqdzcXLlcLr3yyith5Q888IBcLlfYNmPGjLA6p0+f1pw5c+R2u5WRkaEFCxbo7NmzV3UhAADg+hF1QDl37pzGjx+vNWvWfGGdGTNmqLm52dl+8YtfhJXPmTNHhw8f1vbt27Vlyxbt2rVLixYtir71AADgupQU7RtmzpypmTNnXrZOamqqvF5vxLL3339f27Zt0759+zRx4kRJ0k9+8hPNmjVL//7v/67c3NxomwQAAK4z12QNys6dO5WVlaVRo0Zp8eLF+uSTT5yyuro6ZWRkOOFEkoqLi5WQkKA9e/ZEPF5HR4eCwWDYBgAArl89HlBmzJih//qv/1JNTY3+7d/+TbW1tZo5c6a6urokSX6/X1lZWWHvSUpKUmZmpvx+f8RjVldXy+PxOFteXl5PNxsAAFgk6imeL3Pfffc5P48bN06FhYW6+eabtXPnTk2bNq1bx6yqqlJlZaXzOhgMElIAALiOXfPbjG+66SYNHjxYR48elSR5vV61traG1ens7NTp06e/cN1Kamqq3G532AYAAK5f1zygfPTRR/rkk0+Uk5MjSfL5fDpz5ozq6+udOjt27FAoFFJRUdG1bg4AAIgDUU/xnD171hkNkaTjx4+roaFBmZmZyszM1KpVq1RWViav16tjx47pBz/4gUaMGKGSkhJJ0pgxYzRjxgwtXLhQ69at04ULF1RRUaH77ruPO3gAAIAkyWWMMdG8YefOnfrWt751yf758+dr7dq1mj17tvbv368zZ84oNzdX06dP149//GNlZ2c7dU+fPq2Kigq99tprSkhIUFlZmZ577jmlp6dfURuCwaA8Ho8CgQDTPQAAxIloPr+jDig2IKAAABB/ovn85rt4AACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6UX9ZIAD0pM72s/rft1+4bB1XQpJGTH9QLperl1oFINYIKABixhijrs4LCjQdvGw9V2JyL7UIgC2Y4gEQW/H3faUAegEBBUBMGROKdRMAWIiAAiDGGEEBcCkCCoDYYooHQAQEFAAxZQgoACIgoACILdagAIiAgAIgxhhBAXApAgqAmGKKB0AkBBQAsRUioAC4FAEFQEzxHBQAkRBQAMQYIygALkVAARBTrEEBEAkBBUBsEVAAREBAARBTrEEBEAkBBUBsMYICIAICCoCYYgQFQCQEFAAxxggKgEsRUADEFHfxAIgkqoBSXV2tSZMmaeDAgcrKytLs2bPV2NgYVqe9vV3l5eUaNGiQ0tPTVVZWppaWlrA6TU1NKi0tVVpamrKysrRs2TJ1dnZe/dUAiD8EFAARRBVQamtrVV5ert27d2v79u26cOGCpk+frnPnzjl1li5dqtdee02bNm1SbW2tTp48qbvvvtsp7+rqUmlpqc6fP693331XL774otavX69HH320564KQPxgDQqACFzmKsZXT506paysLNXW1ur2229XIBDQkCFDtGHDBt1zzz2SpA8++EBjxoxRXV2dpkyZoq1bt+qOO+7QyZMnlZ2dLUlat26dli9frlOnTiklJeVLzxsMBuXxeBQIBOR2u7vbfAAxZoxR4MRhfbj1ucvWcyUma8KCn8rlcvVSywBcC9F8fl/VGpRAICBJyszMlCTV19frwoULKi4uduqMHj1a+fn5qqurkyTV1dVp3LhxTjiRpJKSEgWDQR0+fDjieTo6OhQMBsM2ANcJpngARNDtgBIKhbRkyRLddtttGjt2rCTJ7/crJSVFGRkZYXWzs7Pl9/udOn8ZTi6WXyyLpLq6Wh6Px9ny8vK622wAlmGRLIBIuh1QysvLdejQIW3cuLEn2xNRVVWVAoGAs504ceKanxNAL2ENCoAIkrrzpoqKCm3ZskW7du3S0KFDnf1er1fnz5/XmTNnwkZRWlpa5PV6nTp79+4NO97Fu3wu1vm81NRUpaamdqepAKzHCAqAS0U1gmKMUUVFhTZv3qwdO3Zo+PDhYeUTJkxQcnKyampqnH2NjY1qamqSz+eTJPl8Ph08eFCtra1One3bt8vtdqugoOBqrgVAHGKKB0AkUY2glJeXa8OGDXr11Vc1cOBAZ82Ix+NR//795fF4tGDBAlVWViozM1Nut1sPPfSQfD6fpkyZIkmaPn26CgoKNHfuXK1evVp+v18rVqxQeXk5oyRAH0RAARBJVAFl7dq1kqSpU6eG7X/hhRf0wAMPSJKefvppJSQkqKysTB0dHSopKdHzzz/v1E1MTNSWLVu0ePFi+Xw+DRgwQPPnz9fjjz9+dVcCID6xBgVABFf1HJRY4TkowPXBGKPTx/bpf2t+dtl6PAcFuD702nNQAOBqxeH/kQD0AgIKgNgioACIgIACIKYMa1AAREBAARBbjKAAiICAAiCmGEEBEAkBBUBsMYICIAICCoDYIqAAiICAAiCmuM0YQCQEFACxxRoUABEQUADEFCMoACIhoACIMQIKgEsRUADEFLcZA4iEgAIgtpjiARABAQVATLEGBUAkBBQAMcYUD4BLEVAAxBYjKAAiIKAAiCmmeABEQkABEFvcxQMgAgIKgJhiBAVAJAQUALFFQAEQAQEFQEwxggIgEgIKgJhqa/7Dl9YZmDOyF1oCwCYEFAAx9enHf/rSOgOG3HjtGwLAKgQUAPZzuWLdAgC9jIACwHouAgrQ5xBQAMQBAgrQ1xBQAFjP5eKfKqCv4a8egP2Y4gH6HAIKAPsRUIA+h4ACwHoskgX6HgIKAPuxBgXoc6L6q6+urtakSZM0cOBAZWVlafbs2WpsbAyrM3XqVLlcrrDtwQcfDKvT1NSk0tJSpaWlKSsrS8uWLVNnZ+fVXw2A6xIjKEDfkxRN5draWpWXl2vSpEnq7OzUD3/4Q02fPl1HjhzRgAEDnHoLFy7U448/7rxOS0tzfu7q6lJpaam8Xq/effddNTc3a968eUpOTtYTTzzRA5cE4LpDQAH6nKgCyrZt28Jer1+/XllZWaqvr9ftt9/u7E9LS5PX6414jDfffFNHjhzRW2+9pezsbN1666368Y9/rOXLl+uxxx5TSkpKNy4DwPWNKR6gr7mqv/pAICBJyszMDNv/0ksvafDgwRo7dqyqqqr06aefOmV1dXUaN26csrOznX0lJSUKBoM6fPhwxPN0dHQoGAyGbQD6DqZ4gL4nqhGUvxQKhbRkyRLddtttGjt2rLP/O9/5joYNG6bc3FwdOHBAy5cvV2Njo15++WVJkt/vDwsnkpzXfr8/4rmqq6u1atWq7jYVQLxjkSzQ53Q7oJSXl+vQoUN65513wvYvWrTI+XncuHHKycnRtGnTdOzYMd18883dOldVVZUqKyud18FgUHl5ed1rOIC4wwgK0Pd0678lFRUV2rJli95++20NHTr0snWLiookSUePHpUkeb1etbS0hNW5+PqL1q2kpqbK7XaHbQD6EgIK0NdEFVCMMaqoqNDmzZu1Y8cODR8+/Evf09DQIEnKycmRJPl8Ph08eFCtra1One3bt8vtdqugoCCa5gDoI1wJTPEAfU1UUzzl5eXasGGDXn31VQ0cONBZM+LxeNS/f38dO3ZMGzZs0KxZszRo0CAdOHBAS5cu1e23367CwkJJ0vTp01VQUKC5c+dq9erV8vv9WrFihcrLy5WamtrzVwgg7jHFA/Q9Uf23ZO3atQoEApo6dapycnKc7Ze//KUkKSUlRW+99ZamT5+u0aNH6+GHH1ZZWZlee+015xiJiYnasmWLEhMT5fP59A//8A+aN29e2HNTACAcAQXoa6IaQTHGXLY8Ly9PtbW1X3qcYcOG6fXXX4/m1AD6Mu7iAfoc/uoBWM+VwAgK0NcQUADEAQIK0NcQUADYj0WyQJ9DQAFgPRdrUIA+h796APZjBAXocwgoAKzHc1CAvoeAAiAOEFCAvoaAAsB+rEEB+hz+6gFYjykeoO8hoACwHgEF6HsIKADiAAEF6GsIKACsx3NQgL6Hv3oA9uO7eIA+h4ACwH6sQQH6HAIKAOsxxQP0PfzVA7AfIyhAn0NAAWA9F3fxAH0OAQWA/ZjiAfoc/uoB2I8pHqDPSYp1AwDEr1AopFAo1P0DGHPF5+nq6ur2aVwulxITE7v9fgC9jxEUAN32r//6r+rfv3+3t7QBaWpvb//S80yeXHRV5/n7v//7XugNAD2JERQA3RYKhdTZ2XnNz3PhQudVnedqRl8AxAYBBYAVznW59fH5r+h8KE1JCR26IcmvjOSPJUmhK5wKAnD9IKAAiLlA52AdavumzoU86jLJSlCn0hLbNCLt98pJ/V8CCtAHEVAAxFR7V7r2nZulC6afsy+kZJ3tytShs7cr2dWuUIiAAvQ1LJIFEFO7/t+9YeHkL3WaFO0Llqq9q38vtwpArBFQAMTUl4+NuJjiAfogAgoA6xkCCtDnEFAAWI81KEDfQ0ABEFO3ZbysBEV+xolLXfr6wDeV7PpzL7cKQKxFFVDWrl2rwsJCud1uud1u+Xw+bd261Slvb29XeXm5Bg0apPT0dJWVlamlpSXsGE1NTSotLVVaWpqysrK0bNmyXnnQEwA7pSf9P032bFFaQkAJuiDJyKVO9Uto09j03yor5Y8y5ioepw8gLkV1m/HQoUP15JNPauTIkTLG6MUXX9Rdd92l/fv365ZbbtHSpUv1m9/8Rps2bZLH41FFRYXuvvtu/e53v5P02dMcS0tL5fV69e6776q5uVnz5s1TcnKynnjiiWtygQDs9tq7f1BS4lG1dR5Uy/kb1R5KV4qrXYNTTiiQ7Nd7ktrP858YoK9xmatcfZaZmamnnnpK99xzj4YMGaINGzbonnvukSR98MEHGjNmjOrq6jRlyhRt3bpVd9xxh06ePKns7GxJ0rp167R8+XKdOnVKKSkpV3TOYDAoj8ejBx544IrfA6Dn1dfXq76+PtbN+FLDhg1TSUlJrJsB9Hnnz5/X+vXrFQgE5Ha7L1u32w9q6+rq0qZNm3Tu3Dn5fD7V19frwoULKi4uduqMHj1a+fn5TkCpq6vTuHHjnHAiSSUlJVq8eLEOHz6sr33taxHP1dHRoY6ODud1MBiUJM2dO1fp6endvQQAV8kYExcBJT8/XwsWLIh1M4A+7+zZs1q/fv0V1Y06oBw8eFA+n0/t7e1KT0/X5s2bVVBQoIaGBqWkpCgjIyOsfnZ2tvx+vyTJ7/eHhZOL5RfLvkh1dbVWrVp1yf6JEyd+aQIDcO385Ro0m91www2aPHlyrJsB9HkXBxiuRNR38YwaNUoNDQ3as2ePFi9erPnz5+vIkSPRHiYqVVVVCgQCznbixIlrej4AABBbUY+gpKSkaMSIEZKkCRMmaN++fXr22Wd177336vz58zpz5kzYKEpLS4u8Xq8kyev1au/evWHHu3iXz8U6kaSmpio1NTXapgIAgDh11c9BCYVC6ujo0IQJE5ScnKyamhqnrLGxUU1NTfL5fJIkn8+ngwcPqrW11amzfft2ud1uFRQUXG1TAADAdSKqEZSqqirNnDlT+fn5amtr04YNG7Rz50698cYb8ng8WrBggSorK5WZmSm3262HHnpIPp9PU6ZMkSRNnz5dBQUFmjt3rlavXi2/368VK1aovLycERIAAOCIKqC0trZq3rx5am5ulsfjUWFhod544w19+9vfliQ9/fTTSkhIUFlZmTo6OlRSUqLnn3/eeX9iYqK2bNmixYsXy+fzacCAAZo/f74ef/zxnr0qAAAQ16IKKD//+c8vW96vXz+tWbNGa9as+cI6w4YN0+uvvx7NaQEAQB/Dd/EAAADrEFAAAIB1CCgAAMA6BBQAAGCdbn8XDwCMHj1as2fPjnUzvhSPuQfiz1V/m3EsXPw24yv5NkQAAGCHaD6/meIBAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsE1VAWbt2rQoLC+V2u+V2u+Xz+bR161anfOrUqXK5XGHbgw8+GHaMpqYmlZaWKi0tTVlZWVq2bJk6Ozt75moAAMB1ISmaykOHDtWTTz6pkSNHyhijF198UXfddZf279+vW265RZK0cOFCPf7448570tLSnJ+7urpUWloqr9erd999V83NzZo3b56Sk5P1xBNP9NAlAQCAeOcyxpirOUBmZqaeeuopLViwQFOnTtWtt96qZ555JmLdrVu36o477tDJkyeVnZ0tSVq3bp2WL1+uU6dOKSUl5YrOGQwG5fF4FAgE5Ha7r6b5AACgl0Tz+d3tNShdXV3auHGjzp07J5/P5+x/6aWXNHjwYI0dO1ZVVVX69NNPnbK6ujqNGzfOCSeSVFJSomAwqMOHD3/huTo6OhQMBsM2AABw/YpqikeSDh48KJ/Pp/b2dqWnp2vz5s0qKCiQJH3nO9/RsGHDlJubqwMHDmj58uVqbGzUyy+/LEny+/1h4USS89rv93/hOaurq7Vq1apomwoAAOJU1AFl1KhRamhoUCAQ0K9//WvNnz9ftbW1Kigo0KJFi5x648aNU05OjqZNm6Zjx47p5ptv7nYjq6qqVFlZ6bwOBoPKy8vr9vEAAIDdop7iSUlJ0YgRIzRhwgRVV1dr/PjxevbZZyPWLSoqkiQdPXpUkuT1etXS0hJW5+Jrr9f7hedMTU117hy6uAEAgOvXVT8HJRQKqaOjI2JZQ0ODJCknJ0eS5PP5dPDgQbW2tjp1tm/fLrfb7UwTAQAARDXFU1VVpZkzZyo/P19tbW3asGGDdu7cqTfeeEPHjh3Thg0bNGvWLA0aNEgHDhzQ0qVLdfvtt6uwsFCSNH36dBUUFGju3LlavXq1/H6/VqxYofLycqWmpl6TCwQAAPEnqoDS2tqqefPmqbm5WR6PR4WFhXrjjTf07W9/WydOnNBbb72lZ555RufOnVNeXp7Kysq0YsUK5/2JiYnasmWLFi9eLJ/PpwEDBmj+/Plhz00BAAC46uegxALPQQEAIP70ynNQAAAArhUCCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnaRYN6A7jDGSpGAwGOOWAACAK3Xxc/vi5/jlxGVAaWtrkyTl5eXFuCUAACBabW1t8ng8l63jMlcSYywTCoXU2NiogoICnThxQm63O9ZNilvBYFB5eXn0Yw+gL3sOfdkz6MeeQ1/2DGOM2tralJubq4SEy68yicsRlISEBH3lK1+RJLndbn5ZegD92HPoy55DX/YM+rHn0JdX78tGTi5ikSwAALAOAQUAAFgnbgNKamqqVq5cqdTU1Fg3Ja7Rjz2Hvuw59GXPoB97Dn3Z++JykSwAALi+xe0ICgAAuH4RUAAAgHUIKAAAwDoEFAAAYJ24DChr1qzRjTfeqH79+qmoqEh79+6NdZOss2vXLt15553Kzc2Vy+XSK6+8ElZujNGjjz6qnJwc9e/fX8XFxfrwww/D6pw+fVpz5syR2+1WRkaGFixYoLNnz/biVcRedXW1Jk2apIEDByorK0uzZ89WY2NjWJ329naVl5dr0KBBSk9PV1lZmVpaWsLqNDU1qbS0VGlpacrKytKyZcvU2dnZm5cSU2vXrlVhYaHzkCufz6etW7c65fRh9z355JNyuVxasmSJs4/+vDKPPfaYXC5X2DZ69GinnH6MMRNnNm7caFJSUsx//ud/msOHD5uFCxeajIwM09LSEuumWeX11183//zP/2xefvllI8ls3rw5rPzJJ580Ho/HvPLKK+Z//ud/zN/+7d+a4cOHmz//+c9OnRkzZpjx48eb3bt3m9/+9rdmxIgR5v777+/lK4mtkpIS88ILL5hDhw6ZhoYGM2vWLJOfn2/Onj3r1HnwwQdNXl6eqampMe+9956ZMmWK+au/+iunvLOz04wdO9YUFxeb/fv3m9dff90MHjzYVFVVxeKSYuK///u/zW9+8xvzhz/8wTQ2Npof/vCHJjk52Rw6dMgYQx921969e82NN95oCgsLzfe+9z1nP/15ZVauXGluueUW09zc7GynTp1yyunH2Iq7gDJ58mRTXl7uvO7q6jK5ubmmuro6hq2y2+cDSigUMl6v1zz11FPOvjNnzpjU1FTzi1/8whhjzJEjR4wks2/fPqfO1q1bjcvlMv/3f//Xa223TWtrq5FkamtrjTGf9VtycrLZtGmTU+f99983kkxdXZ0x5rOwmJCQYPx+v1Nn7dq1xu12m46Ojt69AIvccMMN5mc/+xl92E1tbW1m5MiRZvv27eav//qvnYBCf165lStXmvHjx0csox9jL66meM6fP6/6+noVFxc7+xISElRcXKy6uroYtiy+HD9+XH6/P6wfPR6PioqKnH6sq6tTRkaGJk6c6NQpLi5WQkKC9uzZ0+tttkUgEJAkZWZmSpLq6+t14cKFsL4cPXq08vPzw/py3Lhxys7OduqUlJQoGAzq8OHDvdh6O3R1dWnjxo06d+6cfD4ffdhN5eXlKi0tDes3id/JaH344YfKzc3VTTfdpDlz5qipqUkS/WiDuPqywI8//lhdXV1hvwySlJ2drQ8++CBGrYo/fr9fkiL248Uyv9+vrKyssPKkpCRlZmY6dfqaUCikJUuW6LbbbtPYsWMlfdZPKSkpysjICKv7+b6M1NcXy/qKgwcPyufzqb29Xenp6dq8ebMKCgrU0NBAH0Zp48aN+v3vf699+/ZdUsbv5JUrKirS+vXrNWrUKDU3N2vVqlX65je/qUOHDtGPFoirgALEUnl5uQ4dOqR33nkn1k2JS6NGjVJDQ4MCgYB+/etfa/78+aqtrY11s+LOiRMn9L3vfU/bt29Xv379Yt2cuDZz5kzn58LCQhUVFWnYsGH61a9+pf79+8ewZZDi7C6ewYMHKzEx8ZJV1C0tLfJ6vTFqVfy52FeX60ev16vW1taw8s7OTp0+fbpP9nVFRYW2bNmit99+W0OHDnX2e71enT9/XmfOnAmr//m+jNTXF8v6ipSUFI0YMUITJkxQdXW1xo8fr2effZY+jFJ9fb1aW1v19a9/XUlJSUpKSlJtba2ee+45JSUlKTs7m/7spoyMDH31q1/V0aNH+b20QFwFlJSUFE2YMEE1NTXOvlAopJqaGvl8vhi2LL4MHz5cXq83rB+DwaD27Nnj9KPP59OZM2dUX1/v1NmxY4dCoZCKiop6vc2xYoxRRUWFNm/erB07dmj48OFh5RMmTFBycnJYXzY2NqqpqSmsLw8ePBgW+LZv3y63262CgoLeuRALhUIhdXR00IdRmjZtmg4ePKiGhgZnmzhxoubMmeP8TH92z9mzZ3Xs2DHl5OTwe2mDWK/SjdbGjRtNamqqWb9+vTly5IhZtGiRycjICFtFjc9W+O/fv9/s37/fSDL/8R//Yfbv32/+9Kc/GWM+u804IyPDvPrqq+bAgQPmrrvuinib8de+9jWzZ88e884775iRI0f2uduMFy9ebDwej9m5c2fYrYiffvqpU+fBBx80+fn5ZseOHea9994zPp/P+Hw+p/zirYjTp083DQ0NZtu2bWbIkCF96lbERx55xNTW1prjx4+bAwcOmEceecS4XC7z5ptvGmPow6v1l3fxGEN/XqmHH37Y7Ny50xw/ftz87ne/M8XFxWbw4MGmtbXVGEM/xlrcBRRjjPnJT35i8vPzTUpKipk8ebLZvXt3rJtknbfffttIumSbP3++MeazW41/9KMfmezsbJOammqmTZtmGhsbw47xySefmPvvv9+kp6cbt9ttvvvd75q2trYYXE3sROpDSeaFF15w6vz5z382//RP/2RuuOEGk5aWZv7u7/7ONDc3hx3nj3/8o5k5c6bp37+/GTx4sHn44YfNhQsXevlqYucf//EfzbBhw0xKSooZMmSImTZtmhNOjKEPr9bnAwr9eWXuvfdek5OTY1JSUsxXvvIVc++995qjR4865fRjbLmMMSY2YzcAAACRxdUaFAAA0DcQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgnf8PQ35ud0qF4BIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "env.reset()\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_envs = os.cpu_count()\n",
    "num_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.03234058, -0.03501469, -0.00585138,  0.02065129],\n",
       "        [ 0.02697986, -0.00457622, -0.04344226,  0.02759003],\n",
       "        [ 0.01309526, -0.03154977, -0.03291835, -0.02920913],\n",
       "        [ 0.01766695,  0.01855476,  0.03895122,  0.04163725],\n",
       "        [ 0.00808208,  0.02967859,  0.01478289,  0.0184484 ],\n",
       "        [ 0.02180945,  0.04418165,  0.03506271, -0.03813565],\n",
       "        [ 0.00185848,  0.00121865,  0.03497375,  0.01267837],\n",
       "        [ 0.0340287 , -0.03097538,  0.01543608, -0.04724941],\n",
       "        [ 0.03680797, -0.00330843, -0.00454729,  0.02019916],\n",
       "        [ 0.01776978, -0.02755169, -0.00774339,  0.04613631],\n",
       "        [-0.02789676, -0.00739076,  0.02540836, -0.01188975],\n",
       "        [-0.01945981, -0.04002001,  0.01699855,  0.02697509]],\n",
       "       dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_env = gym.vector.make(\"CartPole-v1\", render_mode=\"rgb_array\", num_envs=num_envs)\n",
    "parallel_env.reset()\n",
    "# plt.imshow(parallel_env.render())\n",
    "# parallel_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessEnv(gym.Wrapper):\n",
    "    def __init__(self, env):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "\n",
    "    def reset(self):\n",
    "        state = self.env.reset()[0]\n",
    "        return torch.from_numpy(np.array(state)).float()\n",
    "\n",
    "    def step(self, actions):\n",
    "        # actions = actions.squeeze().numpy()\n",
    "        actions = np.array(actions)\n",
    "        print(actions)\n",
    "        print(self.env.step(actions))\n",
    "        next_state, reward, done, _, _ = self.env.step([1, 2])\n",
    "        next_state = torch.from_numpy(next_state).float()\n",
    "        reward = torch.tensor(reward).unsqueeze(0).float()\n",
    "        done = torch.tensor(done).unsqueeze(0)\n",
    "        return next_state, reward, done\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_env = PreprocessEnv(parallel_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function AsyncVectorEnv.__del__ at 0x000002086DB8C040>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\async_vector_env.py\", line 546, in __del__\n",
      "    self.close(terminate=True)\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\vector_env.py\", line 205, in close\n",
      "    self.close_extras(**kwargs)\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\async_vector_env.py\", line 461, in close_extras\n",
      "    function(timeout)\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\async_vector_env.py\", line 311, in step_wait\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\async_vector_env.py\", line 493, in _poll\n",
      "    if pipe.closed or (not pipe.poll(delta)):\n",
      "                           ^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\multiprocessing\\connection.py\", line 256, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\multiprocessing\\connection.py\", line 327, in _poll\n",
      "    _winapi.PeekNamedPipe(self._handle)[0] != 0):\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "BrokenPipeError: [WinError 109] The pipe has been ended\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# action = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]])\u001b[39;00m\n\u001b[0;32m      6\u001b[0m action \u001b[38;5;241m=\u001b[39m [[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m----> 7\u001b[0m state, reward, done \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m state, reward, done\n",
      "Cell \u001b[1;32mIn[82], line 13\u001b[0m, in \u001b[0;36mPreprocessEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m     11\u001b[0m actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(actions)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(actions)\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m next_state, reward, done, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m])\n\u001b[0;32m     15\u001b[0m next_state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(next_state)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\vector_env.py:137\u001b[0m, in \u001b[0;36mVectorEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Take an action for each parallel environment.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    Batch of (observations, rewards, terminated, truncated, infos) or (observations, rewards, dones, infos)\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\async_vector_env.py:321\u001b[0m, in \u001b[0;36mAsyncVectorEnv.step_wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pipe \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_pipes):\n\u001b[0;32m    320\u001b[0m     result, success \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mrecv()\n\u001b[1;32m--> 321\u001b[0m     obs, rew, terminated, truncated, info \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m    323\u001b[0m     successes\u001b[38;5;241m.\u001b[39mappend(success)\n\u001b[0;32m    324\u001b[0m     observations_list\u001b[38;5;241m.\u001b[39mappend(obs)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "# parallel_env = gym.vector.make(\"CartPole-v0\", render_mode=\"rgb_array\", num_envs=1)\n",
    "parallel_env = gym.vector.make(\"CartPole-v0\", render_mode=\"rgb_array\", num_envs=2)\n",
    "parallel_env = PreprocessEnv(parallel_env)\n",
    "state = parallel_env.reset()\n",
    "# action = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]])\n",
    "action = [[1]]\n",
    "state, reward, done = parallel_env.step(action)\n",
    "state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = env.observation_space[0]\n",
    "action_dim = env.action_space.n\n",
    "hiddenlayer1 = 128\n",
    "hiddenlayer2 = 64\n",
    "\n",
    "policy = nn.Squential(\n",
    "    nn.Linear(state_dim, hiddenlayer1),\n",
    "    nn.ReLU(),\n",
    "    nn.Liear(hiddenlayer1, hiddenlayer2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hiddenlayer2, action_dim),\n",
    "    nn.softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_state = torch.zeros(4)\n",
    "left_danger = torch.tensor([-2.3, 0., 0., 0.])\n",
    "right_danger = torch.tensor([2.3, 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(neural_state).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(left_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(right_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(policy, episodes, alpha=1e-4, gamma=0.99):\n",
    "    optimizer = torch.optim.AdamW(policy.parameters(), lr=alpha)\n",
    "    stats = {\"Loss\":[], \"Reward\":[]}\n",
    "\n",
    "    for episode in tqdm(range(1, episodes+1)):\n",
    "        state = parallel_env.reset()\n",
    "        done_b = torch.zeros((num_envs, 1), dtype=torch.bool)\n",
    "        transition = []\n",
    "        ep_return = torch.zeros((num_envs, 1))\n",
    "\n",
    "        while not done_b.all():\n",
    "            action = policy(state).multinominal(1).detach()\n",
    "            next_state, reward, done = parallel_env.step(action)\n",
    "            transition.append([state, action, ~done_b * reward])\n",
    "            ep_return += reward\n",
    "            done_b |= done\n",
    "            state = next_state\n",
    "\n",
    "        G = torch.zeros((num_envs, 1))\n",
    "\n",
    "        for t, (state_t, action_t, reward_t) in reversed(list(enumerate(transition))):\n",
    "            G = reward_t + gamma * G\n",
    "            probs_t = policy(state_t)\n",
    "            log_probs_t = torch.log(probs_t + 1e-6)\n",
    "            action_log_prob_t = log_probs_t.gather(1, action_t)\n",
    "\n",
    "            entropy_t = -torch.sum(probs_t * log_probs_t, dim=-1, keepdim=True)\n",
    "            gamma_t = gamma ** t\n",
    "            pg_loss_t = -gamma_t * action_log_prob_t * G\n",
    "            total_loss_t = (pg_loss_t - 0.01 * entropy_t).mean()\n",
    "\n",
    "            policy.zero_grad()\n",
    "            total_loss_t.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        stats[\"Loss\"].append(total_loss_t.item())\n",
    "        stats[\"Return\"].append(ep_return.mean().item())\n",
    "\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_env.reset()\n",
    "stats = reinforce(policy, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(neural_state).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(left_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(right_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policy_network(env, policy, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
