{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Setup code (not important) - Run this cell by pressing \"Shift + Enter\"\n",
    "\n",
    "\n",
    "\n",
    "!pip install -qq gym==0.23.0\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, Optional, Iterable, Callable\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import torch\n",
    "from matplotlib import animation\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "from gym.error import DependencyNotInstalled\n",
    "\n",
    "import pygame\n",
    "from pygame import gfxdraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_video(frames):\n",
    "    # Copied from: https://colab.research.google.com/github/deepmind/dm_control/blob/master/tutorial.ipynb\n",
    "    orig_backend = matplotlib.get_backend()\n",
    "    matplotlib.use('Agg')\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    matplotlib.use(orig_backend)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_position([0, 0, 1, 1])\n",
    "    im = ax.imshow(frames[0])\n",
    "    def update(frame):\n",
    "        im.set_data(frame)\n",
    "        return [im]\n",
    "    anim = animation.FuncAnimation(fig=fig, func=update, frames=frames,\n",
    "                                    interval=50, blit=True, repeat=False)\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "\n",
    "def seed_everything(env: gym.Env, seed: int = 42) -> None:\n",
    "    env.action_space.seed(seed)\n",
    "    env.observation_space.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "def plot_stats(stats):\n",
    "    rows = len(stats)\n",
    "    cols = 1\n",
    "\n",
    "    fig, ax = plt.subplots(rows, cols, figsize=(12, 6))\n",
    "\n",
    "    for i, key in enumerate(stats):\n",
    "        vals = stats[key]\n",
    "        vals = [np.mean(vals[i-10:i+10]) for i in range(10, len(vals)-10)]\n",
    "        if len(stats) > 1:\n",
    "            ax[i].plot(range(len(vals)), vals)\n",
    "            ax[i].set_title(key, size=18)\n",
    "        else:\n",
    "            ax.plot(range(len(vals)), vals)\n",
    "            ax.set_title(key, size=18)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_policy_network(env, policy, episodes=10):\n",
    "    frames = []\n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        frames.append(env.render())\n",
    "\n",
    "        while not done:\n",
    "            state = torch.from_numpy(state).unsqueeze(0).float()\n",
    "            action = policy(state).multinomial(1).item()\n",
    "            next_state, _, done, _ = env.step(action)\n",
    "            img = env.render()\n",
    "            frames.append(img)\n",
    "            state = next_state\n",
    "\n",
    "    return display_video(frames)\n",
    "\n",
    "\n",
    "def plot_action_probs(probs, labels):\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.bar(labels, probs, color ='orange')\n",
    "    plt.title(\"$\\pi(s)$\", size=16)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gym\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "\n",
    "# test_policy_network, seed_everything, plot_state, plot_action_probs, ParallelEnv, ParallelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x285a9c8e310>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v0\", render_mode=\"rgb_array\")\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "env.reset()\n",
    "plt.imshow(env.render())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_envs = os.cpu_count()\n",
    "num_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_env = gym.vector.make(\"CartPole-v1\", render_mode=\"rgb_array\", num_envs=num_envs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessEnv(gym.Wrapper):\n",
    "    def __init__(self, parallel_env):\n",
    "        gym.Wrapper.__init__(self, parallel_env)\n",
    "\n",
    "    def reset(self):\n",
    "        state = self.env.reset()[0]\n",
    "        return torch.from_numpy(np.array(state)).float()\n",
    "\n",
    "    def step_async(self, actions):\n",
    "        actions = actions.squeeze().numpy()\n",
    "        self.env.step_async(actions)\n",
    "\n",
    "    def step_wait(self):\n",
    "        next_state, reward, done, _, _ = self.env.step_wait()\n",
    "        next_state = torch.from_numpy(next_state).float()\n",
    "        reward = torch.tensor(reward.unsqueeze(1).float())\n",
    "        done = torch.tensor(done).unsqueeze(1)\n",
    "        return next_state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_env = PreprocessEnv(parallel_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyPendingCallError",
     "evalue": "Calling `reset_async` while waiting for a pending call to `step` to complete",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyPendingCallError\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m state, rewad, done \u001b[38;5;241m=\u001b[39m parallel_env\u001b[38;5;241m.\u001b[39mstep(torch\u001b[38;5;241m.\u001b[39mzeros(num_envs, \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint32))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Reward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrewad\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Done: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdone\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 6\u001b[0m, in \u001b[0;36mPreprocessEnv.reset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 6\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(state))\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32mc:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\vector_env.py:103\u001b[0m, in \u001b[0;36mVectorEnv.reset\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreset\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m     91\u001b[0m     seed: Optional[Union[\u001b[38;5;28mint\u001b[39m, List[\u001b[38;5;28mint\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m     options: Optional[\u001b[38;5;28mdict\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     93\u001b[0m ):\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reset all parallel environments and return a batch of initial observations.\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m        A batch of observations from the vectorized environment.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_wait(seed\u001b[38;5;241m=\u001b[39mseed, options\u001b[38;5;241m=\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\All Python Projects\\Interpreters\\in_Machine_Learning\\Lib\\site-packages\\gym\\vector\\async_vector_env.py:198\u001b[0m, in \u001b[0;36mAsyncVectorEnv.reset_async\u001b[1;34m(self, seed, options)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(seed) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m!=\u001b[39m AsyncState\u001b[38;5;241m.\u001b[39mDEFAULT:\n\u001b[1;32m--> 198\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m AlreadyPendingCallError(\n\u001b[0;32m    199\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling `reset_async` while waiting for a pending call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` to complete\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[0;32m    201\u001b[0m     )\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pipe, single_seed \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent_pipes, seed):\n\u001b[0;32m    204\u001b[0m     single_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mAlreadyPendingCallError\u001b[0m: Calling `reset_async` while waiting for a pending call to `step` to complete"
     ]
    }
   ],
   "source": [
    "state = parallel_env.reset()\n",
    "state, rewad, done = parallel_env.step(torch.zeros(num_envs, 1, dtype=torch.int32))\n",
    "print(f\"State: {state}, Reward: {rewad}, Done: {done}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = env.observation_space[0]\n",
    "action_dim = env.action_space.n\n",
    "hiddenlayer1 = 128\n",
    "hiddenlayer2 = 64\n",
    "\n",
    "policy = nn.Squential(\n",
    "    nn.Linear(state_dim, hiddenlayer1),\n",
    "    nn.ReLU(),\n",
    "    nn.Liear(hiddenlayer1, hiddenlayer2),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hiddenlayer2, action_dim),\n",
    "    nn.softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_state = torch.zeros(4)\n",
    "left_danger = torch.tensor([-2.3, 0., 0., 0.])\n",
    "right_danger = torch.tensor([2.3, 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(neural_state).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(left_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(right_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforce(policy, episodes, alpha=1e-4, gamma=0.99):\n",
    "    optimizer = torch.optim.AdamW(policy.parameters(), lr=alpha)\n",
    "    stats = {\"Loss\":[], \"Reward\":[]}\n",
    "\n",
    "    for episode in tqdm(range(1, episodes+1)):\n",
    "        state = parallel_env.reset()\n",
    "        done_b = torch.zeros((num_envs, 1), dtype=torch.bool)\n",
    "        transition = []\n",
    "        ep_return = torch.zeros((num_envs, 1))\n",
    "\n",
    "        while not done_b.all():\n",
    "            action = policy(state).multinominal(1).detach()\n",
    "            next_state, reward, done = parallel_env.step(action)\n",
    "            transition.append([state, action, ~done_b * reward])\n",
    "            ep_return += reward\n",
    "            done_b |= done\n",
    "            state = next_state\n",
    "\n",
    "        G = torch.zeros((num_envs, 1))\n",
    "\n",
    "        for t, (state_t, action_t, reward_t) in reversed(list(enumerate(transition))):\n",
    "            G = reward_t + gamma * G\n",
    "            probs_t = policy(state_t)\n",
    "            log_probs_t = torch.log(probs_t + 1e-6)\n",
    "            action_log_prob_t = log_probs_t.gather(1, action_t)\n",
    "\n",
    "            entropy_t = -torch.sum(probs_t * log_probs_t, dim=-1, keepdim=True)\n",
    "            gamma_t = gamma ** t\n",
    "            pg_loss_t = -gamma_t * action_log_prob_t * G\n",
    "            total_loss_t = (pg_loss_t - 0.01 * entropy_t).mean()\n",
    "\n",
    "            policy.zero_grad()\n",
    "            total_loss_t.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        stats[\"Loss\"].append(total_loss_t.item())\n",
    "        stats[\"Return\"].append(ep_return.mean().item())\n",
    "\n",
    "\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_env.reset()\n",
    "stats = reinforce(policy, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stats(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(neural_state).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(left_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = policy(right_danger).detach().numpy()\n",
    "plot_action_probs(probs=probs, labels=[\"Move Left\", \"Move Right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_policy_network(env, policy, episodes=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. if you can do something you should do it. the sign for happyness in peaple is to have a huge house. if you can have it. unless you try but it doesn't change anything. this is ok. Emam Ali: why do you think the God gives us this much profits?\n",
    "\n",
    "2. آیا فقر باعث از بین رفتن دین میشود یا برعکس؟ اگر در جامعه ای فقر بیشتر شود، جرم و جنایت زیاد میشود و در نتیجه نقطه مقابل دینداری هست. لذادراز این منظر نظریه فقر دچار مشکل است. اگر به یک خانه فقر وارد شود از در دیگر ایمان خارج میشود.\n",
    "\n",
    "3. ایده اقای مارکس این است که از فقر انسان ها فقر متولد میشود و ادامه پیدا میکند.\n",
    "\n",
    "4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
